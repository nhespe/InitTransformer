# InitTransformer

This repository is focused on learning what the transformer does under the hood, instead of relying on whatever helper /wrapper functions are implemented in PyTorch or HuggingFace

It starts with:\n
 \nWIP process_sequence.py: Which is focused on prepping text for S2S problems
 \nWIP transformer_code.py: Classes of the basic Transformer Architecture: Following: https://towardsdatascience.com/how-to-code-the-transformer-in-pytorch-24db27c8f9ec
